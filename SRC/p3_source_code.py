# -*- coding: utf-8 -*-
"""P3_Source_Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SqbPVyaiCQ72dRX1UW9Jv3URC3Ex2s0V

# DS 4002 Project 3

## Data Cleaning
"""

#Standard imports
import pandas as pd
import numpy as np

#Install and import package for continents
!pip install pycountry_convert
import pycountry_convert as pc

#Read in data
WHR = pd.read_excel(r"/content/WHR Data.xls")

#Original number of countries
WHR["Country name"].nunique()

#Drop rows with nan values
WHR = WHR.dropna()
#Drop irrelevant columns
WHR = WHR.drop(columns=["Positive affect","Negative affect"])
#Rename columns to more user friendly names
WHR = WHR.rename(columns={"Country name":"Country","year":"Year","Life Ladder":"Happiness Score","Log GDP per capita":"Log GDP per Cap","Social support":"Social Support","Healthy life expectancy at birth":"Life Expectancy",
                    "Freedom to make life choices":"Freedom","Perceptions of corruption":"Corruption"})

#Select only countries with complete data from 2013 to 2019
WHR = WHR[WHR["Year"].isin(range(2013,2020))]
countries = np.unique(WHR["Country"], return_counts=True)[0]
occurances = np.unique(WHR["Country"], return_counts=True)[1] == 7
dropCountries = countries[np.where(occurances)]
WHR = WHR[WHR["Country"].isin(dropCountries)]

WHR

#Rename countries with different names to alpha-2 country code list
WHR["Country"] = WHR["Country"].replace(["Congo (Brazzaville)","Turkiye"],["Congo","Turkey"])

#New number of countries
WHR["Country"].nunique()

#Set dataframe index to Country so it's easier to drop countries
WHR = WHR.set_index("Country")

#Assign continents
WHR["Country Code"] = WHR.index.map(lambda x: pc.country_name_to_country_alpha2(x, cn_name_format="default"))
WHR["Continent Code"] = WHR["Country Code"].map(lambda x: pc.country_alpha2_to_continent_code(x))
WHR["Continent"] = WHR["Continent Code"].map(lambda x: pc.convert_continent_code_to_continent_name(x))
WHR = WHR.drop(columns=["Country Code", "Continent Code"]).reset_index()

#Cleaned dataset
WHR

#Exporting dataset
WHR.to_csv('WHR.csv', index=False)

"""## Data Vizualization"""

#Data viz import
import plotly.express as px

#Happiness Score by Continent over Time
px.line(WHR.groupby(by=["Continent","Year"]).agg("mean").reset_index(),"Year","Happiness Score",color="Continent")

#Happiness Score vs GDP
px.scatter(WHR, "Log GDP per Cap", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. GDP")

#Happiness Score vs Social Support
px.scatter(WHR, "Social Support", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. Social Support")

#Happiness Score vs Life Expectancy
px.scatter(WHR, "Life Expectancy", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. Life Expectancy")

#Happiness Score vs Freedom
px.scatter(WHR, "Freedom", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. Freedom")

#Happiness Score vs Generosity
px.scatter(WHR, "Generosity", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. Generosity")

#Happiness Score vs Corruption
px.scatter(WHR, "Corruption", "Happiness Score", color = "Continent", hover_name = "Country", animation_frame="Year", animation_group="Country", title="Happiness Score vs. Corruption")

"""## Machine Learning"""

WHR = pd.read_csv(r"/content/WHR.csv")

WHR.head()

#Machine learning imports
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

#Keep columns relavent for ML
ML_WHR = WHR.drop(columns=["Country", "Year", "Continent", "Generosity", "Corruption"])

#Divide into X & y
X = StandardScaler().fit_transform(ML_WHR.drop(columns=["Happiness Score"]))
y = ML_WHR["Happiness Score"]
#Split data
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
#Create and train model
mult_reg = LinearRegression()
mult_reg.fit(X_train,y_train)

#Generate Predictions
predicted = mult_reg.predict(X_test)
actual = np.array(y_test)

#MSE & RMSE
mse = mean_squared_error(predicted,actual)
rmse = mean_squared_error(predicted,actual,squared=False)
print("MSE is ", round(mse,5), " and RMSE is ", round(rmse,5))

#Beta Coefficients
coef = np.around(mult_reg.coef_,3)
intercept = round(mult_reg.intercept_,3)
factor_impact = (coef - coef[3]) / coef[3]

print(factor_impact)

#Multiple Linear Regression Equation
print("Score =", coef[0],"*GDPperCap +", coef[1],"*SocialSup +",coef[2],"*LifeExpect +",coef[3],"*Freedom +", intercept)

"""## Future Analysis"""

WHR22 = pd.read_excel(r"/content/WHR Data.xls")

#Drop rows with nan values
WHR22 = WHR22.dropna()
#Drop irrelevant columns
WHR22 = WHR22.drop(columns=["Positive affect","Negative affect"])
#Rename columns to more user friendly names
WHR22 = WHR22.rename(columns={"Country name":"Country","year":"Year","Life Ladder":"Happiness Score","Log GDP per capita":"Log GDP per Cap","Social support":"Social Support","Healthy life expectancy at birth":"Life Expectancy",
                    "Freedom to make life choices":"Freedom","Perceptions of corruption":"Corruption"})

#Select only 2022 data
WHR22 = WHR22[WHR22["Year"] == 2022].reset_index(drop=True)

#Scale factors just as they were done for ML
WHR22[["Log GDP per Cap","Social Support","Life Expectancy","Freedom"]] = StandardScaler().fit_transform(WHR22[["Log GDP per Cap","Social Support","Life Expectancy","Freedom"]])

WHR22

#Create new column with predictions
predictions = []
for i in WHR22.index:
   predictions = np.append(predictions, coef[0]*WHR22["Log GDP per Cap"][i] + coef[1]*WHR22["Social Support"][i] + coef[2]*WHR22["Life Expectancy"][i] +
                           coef[3]*WHR22["Freedom"][i] + intercept)
WHR22["Predicted Happiness Score"] = predictions

WHR22

#MSE & RMSE
mse = mean_squared_error(predictions,WHR22["Happiness Score"])
rmse = mean_squared_error(predictions,WHR22["Happiness Score"],squared=False)
print("MSE is ", round(mse,5), " and RMSE is ", round(rmse,5))